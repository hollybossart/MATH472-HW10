{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  # Homework 10\n",
    "\n",
    "  First Last\n",
    "\n",
    "  2020-04-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ipython().run_line_magic('matplotlib', 'widget')\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "# get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
    "# plt.rcParams['figure.figsize'] = (9, 5.5)\n",
    "# mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "# mpl.rcParams['font.size'] = 14\n",
    "# mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ## Problem 1: Transformation of Random Variables\n",
    "\n",
    " Given that $X \\sim \\mathrm{Unif}(0, 1)$, let\n",
    "\n",
    " $$Y = \\mathrm{logit}(X) \\equiv \\log \\left( \\frac{X}{1 - X} \\right)$$\n",
    "\n",
    " Find the probability density function (PDF) of Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <br/>\n",
    " <br/>\n",
    "\n",
    " ## Problem 2: Problem 7.1 on page 230 of _Computational Statistics_\n",
    "\n",
    " ---\n",
    "\n",
    " ### Problem 7.1 Metropolis-Hastings\n",
    "\n",
    " The goal of this problem is to investigate the role of the proposal\n",
    " distribution in a Metropolis-Hastings algorithm designed to simulate from the\n",
    " posterior distribution of a parameter $\\delta$. In part (a), you are asked to\n",
    " simulate data from a distribution with $\\delta$ known. For parts (b)-(d),\n",
    " provide an appropriate plot and a table summarizing the output of the\n",
    " algorithm. To facilitate comparisons, use the same number of iterations,\n",
    " random seed, starting values, and burn-in period for all implementations of\n",
    " the algorithm.\n",
    "\n",
    " * (a) Simulate 200 realizations from the mixture distribution in Equation\n",
    "   (7.6) with $\\delta = 0.7$. Draw a histogram of these data.\n",
    "\n",
    " > (Eq. 7.6):\n",
    " >\n",
    " > $\\delta N(7, 0.5^2) + (1 - \\delta) N(10, 0.5^2)$\n",
    "\n",
    " * (b) Implement an independence chain MCMC procedure to simulate from the\n",
    "   posterior distribution of $\\delta$, using your data from part (a)\n",
    "\n",
    " * (c) Implement a random walk chain with $\\delta^* = \\delta^{(t)} +\n",
    "   \\epsilon$ with $\\epsilon \\sim \\mathrm{Unif}(-1, 1)$.\n",
    "\n",
    " * (d) Reparameterize the problem letting $U = \\log \\left[ \\delta / (1 -\n",
    "   \\delta) \\right]$ and $U^* = u^{(t)} + \\epsilon$. Implement a random walk\n",
    "   chain in $U$-space as in equation (7.8).\n",
    "\n",
    " > (Eq. 7.8):\n",
    " >\n",
    " > $\\frac{f\\left(\\mathrm{logit}^{-1}\\{u^*\\}\\right)\\ | J(u^*) |\\ g \\left(u^{(t)} | u^*\\right)}\n",
    "   {f\\left(\\mathrm{logit}^{-1}\\{u^{(t)}\\}\\right)\\ | J(u^{(t)}) |\\ g \\left(u^* | u^{(t)}\\right)}$\n",
    "\n",
    " * (e) Compare the estimates and convergence behavior of the three algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <br/>\n",
    " <br/>\n",
    "\n",
    " ## Problem 3: Problem 7.2 on page 231 of _Computational Statistics_\n",
    "\n",
    " ---\n",
    "\n",
    " ### Problem 7.2 - Simulating realizations\n",
    "\n",
    " Simulating from the mixture distribution in Equation (7.6) is straightforward\n",
    " [see part (a) of Problem 7.1]. However, using the Metropolis-Hastings\n",
    " algorithm to simulate realizations from this distribution is useful for\n",
    " exploring the role of the proposal distribution.\n",
    "\n",
    " * (a) Implement a Metropolis-hastings algorithm to simulate from Equation\n",
    "   (7.6) with $\\delta = 0.7$, using $N(x^{(t)}, 0.01^2)$ as the proposal\n",
    "   distribution. For each of three starting values, $x^{(0)} = 0,\\ 7,\n",
    "   $ and $15$, run the chain for 10,000 iterations. Plot the sample path\n",
    "   of the output from each chain. If only one of the sample paths was\n",
    "   available, what would you conclude about the chain? For each of the\n",
    "   simulations, creat a histogram of the realizations with the true density\n",
    "   superimposed on the historam. Based on your output from all three chains,\n",
    "   what can you say about the behavior of the chain?\n",
    "\n",
    " > (Eq. 7.6):\n",
    " >\n",
    " > $\\delta N(7, 0.5^2) + (1 - \\delta) N(10, 0.5^2)$\n",
    "\n",
    " * (b) Now change the proposal distribution to imporove the convergence\n",
    "   properties of the chain. using the new proposal distribution, repeat part\n",
    "   (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
